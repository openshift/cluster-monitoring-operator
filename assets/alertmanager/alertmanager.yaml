apiVersion: monitoring.coreos.com/v1
kind: Alertmanager
metadata:
  labels:
    alertmanager: main
    app.kubernetes.io/component: alert-router
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/part-of: openshift-monitoring
    app.kubernetes.io/version: 0.22.2
  name: main
  namespace: openshift-monitoring
spec:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - podAffinityTerm:
          labelSelector:
            matchLabels:
              app.kubernetes.io/component: alert-router
              app.kubernetes.io/name: alertmanager
              app.kubernetes.io/part-of: openshift-monitoring
          namespaces:
          - openshift-monitoring
          topologyKey: kubernetes.io/hostname
        weight: 100
  containers:
  - args:
    - -provider=openshift
    - -https-address=:9095
    - -http-address=
    - -email-domain=*
    - -upstream=http://localhost:9093
    - '-openshift-sar=[{"resource": "namespaces", "verb": "get"}, {"resource": "alertmanagers",
      "resourceAPIGroup": "monitoring.coreos.com", "namespace": "openshift-monitoring",
      "verb": "patch", "resourceName": "non-existant"}]'
    - '-openshift-delegate-urls={"/": {"resource": "namespaces", "verb": "get"}, "/":
      {"resource":"alertmanagers", "group": "monitoring.coreos.com", "namespace":
      "openshift-monitoring", "verb": "patch", "name": "non-existant"}}'
    - -tls-cert=/etc/tls/private/tls.crt
    - -tls-key=/etc/tls/private/tls.key
    - -client-secret-file=/var/run/secrets/kubernetes.io/serviceaccount/token
    - -cookie-secret-file=/etc/proxy/secrets/session_secret
    - -openshift-service-account=alertmanager-main
    - -openshift-ca=/etc/pki/tls/cert.pem
    - -openshift-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    env:
    - name: HTTP_PROXY
      value: ""
    - name: HTTPS_PROXY
      value: ""
    - name: NO_PROXY
      value: ""
    image: quay.io/openshift/oauth-proxy:latest
    name: alertmanager-proxy
    ports:
    - containerPort: 9095
      name: web
    resources:
      requests:
        cpu: 1m
        memory: 20Mi
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/tls/private
      name: secret-alertmanager-main-tls
    - mountPath: /etc/proxy/secrets
      name: secret-alertmanager-main-proxy
  - args:
    - --secure-listen-address=0.0.0.0:9092
    - --upstream=http://127.0.0.1:9096
    - --config-file=/etc/kube-rbac-proxy/config.yaml
    - --tls-cert-file=/etc/tls/private/tls.crt
    - --tls-private-key-file=/etc/tls/private/tls.key
    - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
    - --logtostderr=true
    - --v=10
    image: quay.io/brancz/kube-rbac-proxy:v0.11.0
    name: kube-rbac-proxy
    ports:
    - containerPort: 9092
      name: tenancy
    resources:
      requests:
        cpu: 1m
        memory: 15Mi
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kube-rbac-proxy
      name: secret-alertmanager-kube-rbac-proxy
    - mountPath: /etc/tls/private
      name: secret-alertmanager-main-tls
  - args:
    - --secure-listen-address=0.0.0.0:8081
    - --upstream=http://127.0.0.1:8080
    - --tls-cert-file=/etc/tls/private/tls.crt
    - --tls-private-key-file=/etc/tls/private/tls.key
    - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
    - --logtostderr=true
    - --v=10
    image: quay.io/brancz/kube-rbac-proxy:v0.11.0
    name: kube-rbac-proxy-alertmanager-config-reloader
    ports:
    - containerPort: 8081
      name: config-reloader
    resources:
      requests:
        cpu: 1m
        memory: 15Mi
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/tls/private
      name: secret-alertmanager-main-tls
  - args:
    - --insecure-listen-address=127.0.0.1:9096
    - --upstream=http://127.0.0.1:9093
    - --label=namespace
    image: quay.io/prometheuscommunity/prom-label-proxy:v0.3.0
    name: prom-label-proxy
    resources:
      requests:
        cpu: 1m
        memory: 20Mi
    terminationMessagePolicy: FallbackToLogsOnError
  - name: config-reloader
    resources:
      requests:
        cpu: 1m
        memory: 10Mi
  image: quay.io/prometheus/alertmanager:v0.22.2
  listenLocal: true
  nodeSelector:
    kubernetes.io/os: linux
  podMetadata:
    annotations:
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    labels:
      app.kubernetes.io/component: alert-router
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 0.22.2
  priorityClassName: system-cluster-critical
  replicas: 3
  resources:
    requests:
      cpu: 4m
      memory: 40Mi
  secrets:
  - alertmanager-main-tls
  - alertmanager-main-proxy
  - alertmanager-kube-rbac-proxy
  securityContext:
    fsGroup: 65534
    runAsNonRoot: true
    runAsUser: 65534
  serviceAccountName: alertmanager-main
  version: 0.22.2
