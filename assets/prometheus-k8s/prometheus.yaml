apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  labels:
    app.kubernetes.io/component: prometheus
    app.kubernetes.io/instance: k8s
    app.kubernetes.io/managed-by: cluster-monitoring-operator
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: openshift-monitoring
    app.kubernetes.io/version: 2.50.1
  name: k8s
  namespace: openshift-monitoring
spec:
  additionalAlertRelabelConfigs:
    key: config.yaml
    name: alert-relabel-configs
    optional: true
  additionalArgs:
  - name: scrape.timestamp-tolerance
    value: 15ms
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: prometheus
            app.kubernetes.io/instance: k8s
            app.kubernetes.io/name: prometheus
            app.kubernetes.io/part-of: openshift-monitoring
        namespaces:
        - openshift-monitoring
        topologyKey: kubernetes.io/hostname
  alerting:
    alertmanagers:
    - apiVersion: v2
      bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
      name: alertmanager-main
      namespace: openshift-monitoring
      port: web
      scheme: https
      tlsConfig:
        caFile: /etc/prometheus/configmaps/serving-certs-ca-bundle/service-ca.crt
        serverName: alertmanager-main
  configMaps:
  - serving-certs-ca-bundle
  - kubelet-serving-ca-bundle
  - metrics-client-ca
  containers:
  - args:
    - --secure-listen-address=0.0.0.0:9091
    - --upstream=http://127.0.0.1:9090
    - --config-file=/etc/kube-rbac-proxy/config.yaml
    - --tls-cert-file=/etc/tls/private/tls.crt
    - --tls-private-key-file=/etc/tls/private/tls.key
    - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
    - --ignore-paths=/-/healthy,/-/ready
    image: quay.io/brancz/kube-rbac-proxy:v0.15.0
    name: kube-rbac-proxy-web
    ports:
    - containerPort: 9091
      name: web
    resources:
      requests:
        cpu: 1m
        memory: 15Mi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/tls/private
      name: secret-prometheus-k8s-tls
    - mountPath: /etc/kube-rbac-proxy
      name: secret-prometheus-k8s-kube-rbac-proxy-web
  - args:
    - --secure-listen-address=0.0.0.0:9092
    - --upstream=http://127.0.0.1:9090
    - --allow-paths=/metrics,/federate
    - --config-file=/etc/kube-rbac-proxy/config.yaml
    - --tls-cert-file=/etc/tls/private/tls.crt
    - --tls-private-key-file=/etc/tls/private/tls.key
    - --client-ca-file=/etc/tls/client/client-ca.crt
    - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
    image: quay.io/brancz/kube-rbac-proxy:v0.15.0
    name: kube-rbac-proxy
    ports:
    - containerPort: 9092
      name: metrics
    resources:
      requests:
        cpu: 1m
        memory: 15Mi
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/tls/private
      name: secret-prometheus-k8s-tls
    - mountPath: /etc/tls/client
      name: configmap-metrics-client-ca
      readOnly: true
    - mountPath: /etc/kube-rbac-proxy
      name: secret-kube-rbac-proxy
  - args:
    - --secure-listen-address=[$(POD_IP)]:10903
    - --upstream=http://127.0.0.1:10902
    - --tls-cert-file=/etc/tls/private/tls.crt
    - --tls-private-key-file=/etc/tls/private/tls.key
    - --client-ca-file=/etc/tls/client/client-ca.crt
    - --config-file=/etc/kube-rbac-proxy/config.yaml
    - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
    - --allow-paths=/metrics
    - --logtostderr=true
    env:
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    image: quay.io/brancz/kube-rbac-proxy:v0.15.0
    name: kube-rbac-proxy-thanos
    ports:
    - containerPort: 10903
      name: thanos-proxy
    resources:
      requests:
        cpu: 1m
        memory: 10Mi
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/tls/private
      name: secret-prometheus-k8s-thanos-sidecar-tls
      readOnly: true
    - mountPath: /etc/kube-rbac-proxy
      name: secret-kube-rbac-proxy
      readOnly: true
    - mountPath: /etc/tls/client
      name: configmap-metrics-client-ca
      readOnly: true
  - args:
    - sidecar
    - --prometheus.url=http://localhost:9090/
    - --tsdb.path=/prometheus
    - --http-address=127.0.0.1:10902
    - --grpc-server-tls-cert=/etc/tls/grpc/server.crt
    - --grpc-server-tls-key=/etc/tls/grpc/server.key
    - --grpc-server-tls-client-ca=/etc/tls/grpc/ca.crt
    name: thanos-sidecar
    resources:
      requests:
        cpu: 1m
        memory: 25Mi
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/tls/grpc
      name: secret-grpc-tls
  - name: prometheus
    terminationMessagePolicy: FallbackToLogsOnError
  enableFeatures: []
  externalLabels: {}
  externalURL: https://prometheus-k8s.openshift-monitoring.svc:9091
  image: quay.io/prometheus/prometheus:v2.50.1
  listenLocal: true
  maximumStartupDurationSeconds: 3600
  nodeSelector:
    kubernetes.io/os: linux
  podMetadata:
    annotations:
      target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
    labels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: openshift-monitoring
      app.kubernetes.io/version: 2.50.1
  podMonitorNamespaceSelector:
    matchLabels:
      openshift.io/cluster-monitoring: "true"
  podMonitorSelector: {}
  priorityClassName: system-cluster-critical
  probeNamespaceSelector:
    matchLabels:
      openshift.io/cluster-monitoring: "true"
  probeSelector: {}
  replicas: 2
  resources:
    requests:
      cpu: 70m
      memory: 1Gi
  ruleNamespaceSelector:
    matchLabels:
      openshift.io/cluster-monitoring: "true"
  ruleSelector: {}
  scrapeConfigNamespaceSelector: null
  scrapeConfigSelector: null
  secrets:
  - prometheus-k8s-tls
  - prometheus-k8s-thanos-sidecar-tls
  - kube-rbac-proxy
  - prometheus-k8s-kube-rbac-proxy-web
  - metrics-client-certs
  securityContext:
    fsGroup: 65534
    runAsNonRoot: true
    runAsUser: 65534
  serviceAccountName: prometheus-k8s
  serviceMonitorNamespaceSelector:
    matchLabels:
      openshift.io/cluster-monitoring: "true"
  serviceMonitorSelector: {}
  thanos:
    image: quay.io/thanos/thanos:v0.34.0
    resources:
      requests:
        cpu: 1m
        memory: 100Mi
    version: 0.34.0
  version: 2.50.1
  web:
    httpConfig:
      headers:
        contentSecurityPolicy: frame-ancestors 'none'
